{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regress√£o Linear - Teoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regress√£o linear √© uma t√©cnica de Machine Learning (Aprendizado de M√°quina) - um dos campos de Intelig√™ncia Artificial - que consiste em tentar descobrir uma rela√ß√£o linear entre os dados utilizados no treinamento da m√°quina para poder prever/inferir algo sobre esses dados. \n",
    "\n",
    "Em outras palavras, √© tentar encontrar uma rela√ß√£o de car√°ter linear entre as vari√°veis dadas como entrada e as vari√°veis dadas como sa√≠da. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¢ Matem√°tica do Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üíæ Dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A seguir estamos representando a matem√°tica do 'modelo' em si. Vamos considerar que os dados s√£o representados pela matriz $X \\in \\mathbb{R}^{n \\times m}$, ou seja, temos $n$ exemplos, amostras, e cada um desses exemplos t√™m $m$ atributos, qualidades. Ou seja, √© como se cada linha representasse um dos itens.\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix*}[r] \n",
    "x_{11} & \\dots & x_{1m} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n1} & \\dots & x_{nm} \\\\\n",
    "\\end{pmatrix*} \n",
    "$$\n",
    "\n",
    "Para exemplificar, imagine que cada linha representa um local e que cada n√∫mero da linha representa um atributo destes locais. Exemplo: a primeira coordenada pode indicar a temperatura m√©dia do local, a segunda a densidade populacional, a terceira o n√∫mero de ve√≠culos e etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚öñÔ∏è Vetor de pesos & Bias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia, continuando o exemplo anterior, poderia ser medir o custo m√©dio de hotel desses lugares pautando-se nos atributos que temos dispon√≠veis. Assim, colocamos os dados no modelo a fim de descobrir de conseguimos estabelecer uma rela√ß√£o linear entre os atributos e o resultado final (o valor m√©dio do custo de hospedagem). \n",
    "\n",
    "Para isso, temos um **vetor de pesos** $w \\in \\mathbb{R}^{m}$, que estabelece \"o qu√£o importante\", o qu√£o 'pesado', √© aquele atributo para o resultado final. Por isso o vetor tem 'm' elementos, um peso para cada um dos atributos. \n",
    "\n",
    "Tamb√©m temos um outro vetor, o **bias**, $b \\in \\mathbb{R}^{n}$, que serve apenas de ajuste para o que os dados possam se ajustar melhor ao modelo, dado sua simplifica√ß√£o. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ûï A opera√ß√£o:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O modelo sup√µe que podemos determinar os **r√≥tulos** por uma rela√ß√£o linear do tipo:\n",
    "\n",
    "$$≈∂ = Xw + b$$\n",
    "$$\n",
    "\\begin{pmatrix*}[r] \n",
    "x_{11} & \\dots & x_{1m} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n1} & \\dots & x_{nm} \\\\\n",
    "\\end{pmatrix*} \n",
    ".\n",
    "\\begin{pmatrix*}[r] \n",
    "w_1 \\\\\n",
    "\\vdots \\\\\n",
    "w_m \\\\\n",
    "\\end{pmatrix*} \n",
    "\n",
    "+ \n",
    "\\begin{pmatrix*}[r] \n",
    "B_1 \\\\\n",
    "\\vdots \\\\\n",
    "B_n \\\\\n",
    "\\end{pmatrix*} \n",
    "\n",
    "= \n",
    "\n",
    "\\begin{pmatrix*}[r] \n",
    "≈∑_1 \\\\\n",
    "\\vdots \\\\\n",
    "≈∑_n \\\\\n",
    "\\end{pmatrix*} \n",
    "$$\n",
    "\n",
    "Para a representa√ß√£o do c√°lculo do r√≥tulo de cada exemplo (linha), temos:\n",
    "\n",
    "$$≈∑_i = w_1 . x_{i1} + ... + w_m . x_{im} + B = w^T.x + B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Fun√ß√µes do Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚è≠Ô∏è Fun√ß√£o Forward:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia da fun√ß√£o **forward** √© realizar o c√°lculo explicado anteriormente de previs√£o do modelo:\n",
    "\n",
    "$$≈∂ = Xw + b$$\n",
    "$$\n",
    "\\begin{pmatrix*}[r] \n",
    "x_{11} & \\dots & x_{1m} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n1} & \\dots & x_{nm} \\\\\n",
    "\\end{pmatrix*} \n",
    ".\n",
    "\\begin{pmatrix*}[r] \n",
    "w_1 \\\\\n",
    "\\vdots \\\\\n",
    "w_m \\\\\n",
    "\\end{pmatrix*} \n",
    "\n",
    "+ \n",
    "\\begin{pmatrix*}[r] \n",
    "B_1 \\\\\n",
    "\\vdots \\\\\n",
    "B_n \\\\\n",
    "\\end{pmatrix*} \n",
    "\n",
    "= \n",
    "\n",
    "\\begin{pmatrix*}[r] \n",
    "≈∑_1 \\\\\n",
    "\\vdots \\\\\n",
    "≈∑_n \\\\\n",
    "\\end{pmatrix*} \n",
    "$$\n",
    "\n",
    "Veja um exemplo de c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere W -> Vetor de Pesos;\n",
    "W = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Considere b -> Vetor de bias;\n",
    "B = torch.tensor(-1.0, requires_grad=True)\n",
    "\n",
    "# Fun√ß√£o Forward:\n",
    "def forward(x):\n",
    "    return W * x + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fun√ß√£o recebe uma entrada, multiplica ela pelo vetor de pesos e adiciona o bias, devolvendo um vetor de previs√µes/infer√™ncias de r√≥tulos para aquela colet√¢nea de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìâ Fun√ß√£o de Perda:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **fun√ß√£o de perda** permite calcular o quanto a sua aproxima√ß√£o pela rela√ß√£o linear exposta anteriomente est√° se aproximando da realidade. Existem v√°rios tipos de fun√ß√µes de perda, mas a ideia √© sempre a mesma, que √© comparar o que foi previsto/calculado utilizando o modelo adotado com a realidade dos dados que temos. \n",
    "\n",
    "Nessa implementa√ß√£o, iremos utilizar o **erro quadr√°tico**:\n",
    "\n",
    "$$l^i(w, b) = \\frac{1}{2} (≈∑^i - y^i)¬≤$$\n",
    "\n",
    "$$L(w, b) = \\frac{1}{n}\\sum_{i = 1}^{n}{l^i(w, B)}  = \\frac{1}{n}\\sum_{i = 1}^{n}{\\frac{1}{2}(w^Tx^i + b - y^i)^2}$$\n",
    "\n",
    "A primeira fun√ß√£o, $l^i(w, b)$ representa o erro da previs√£o feita pelo modelo, $≈∑^i$, para o i-√©simo exemplo/linha dos dados que temos. Note que a fun√ß√£o $l^i$ recebe $w$ e $b$ como par√¢metros, pois o modelo faz infer√™ncias a partir desses par√¢metros. \n",
    "\n",
    "O somat√≥rio abaixo representa a m√©dia dos erros de cada um dos *n* exemplos dos dados (lembrando, √© claro, que os dados ser√£o partidos em teste e treino). \n",
    "\n",
    "A fun√ß√£o de perda √© importantiss√≠ma, pois √© ela que guia como iremos alterar o **vetor de pesos** e o **bias**, pois a ideia √© tentar minimizar seu valor ao m√°ximo. Veja a seguir a implementa√ß√£o do c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y, y_pred):\n",
    "    return ((y_pred - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ú® O Treino e a Otimiza√ß√£o:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir disso, da fun√ß√£o **forward** para calcular os r√≥tulos a partir do vetor de pesos e do bias e da fun√ß√£o de **perda** para qualificar o modelo, podemos ir atualizando o valor de pesos e treinando o modelo para tentar melhorar a rela√ß√£o linear que estamos tentando encontrar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà Estrat√©gia de Otimiza√ß√£o:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao passarmos pelos dados, podemos obtee o **gradiente** da fun√ß√£o de perda considerando os dados utilizados e em respeito aos par√¢metros $w$ e $b$. O gradiente aponta para a dire√ß√£o de crescimento do valor da fun√ß√£o. Como desejamos reduzir o valor da fun√ß√£o de perda, iremos atualizar os valores do $w$ e do $b$ na dire√ß√£o oposta do gradiente. \n",
    "\n",
    "Ap√≥s esse c√°lculo, vamos atualizar os par√¢metros para tentar reduzir o valor do erro calculado, esse √© nosso **step**. Veja abaixo a representa√ß√£o matem√°tica desse passo:\n",
    "\n",
    "$$ (w, b) = (w, b) - \\alpha . \\frac{1}{n_{\\mathbb{b}}} \\sum_{i \\in \\mathbb{b}}  ‚àÇ_{(w, b)} l^i(w,b)$$\n",
    "\n",
    "$$l^i(w, b) = (w^Tx^i+ b - y^i)^2$$\n",
    "\n",
    "Com $\\alpha$ sendo o **learning rate**, que representa a 'intensidade' da atualiza√ß√£o dos par√¢metros. \n",
    "\n",
    "Note que o somat√≥rio √© um **tensor**, e as coordenadas desse tensor representam a dire√ß√£o em que a fun√ß√£o de perda cresce considerando os dados utilizados. Por tal motivo, realizamos a subtra√ß√£o para ir na dire√ß√£o oposta, ou seja, na dire√ß√£o em que o valor est√° sendo diminu√≠do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèãÔ∏è‚Äç‚ôÇÔ∏è Treinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ap√≥s codar tudo isso, basta treinar o modelo e ir atualizando o vetor de pesos e o bias at√© atingir um ponto que pare√ßa ser aceit√°vel, avaliando a precis√£o do modelo. \n",
    "\n",
    "Cada itera√ß√£o completa pelos dados de treino √© chamada de **√âpoca**. Para treinar o modelo √© necess√°rio ent√£o escolher, de √≠nicio de forma arbitr√°tia/perceptiva o n√∫mero de √©pocas e o learning rate. Interessante notar que em quanto menor for o *learning rate*, mais √©pocas ser√£o necess√°rias para que o modelo convirja. E com um *learning rate* muito alto, h√° o risco de o modelo nem se quer convergir. \n",
    "\n",
    "√â claro que esses problemas de convergimento do modelo envolvem v√°rios outros componentes e rela√ß√µes, e podem surgir outros problemas que n√£o conv√©m explicar no momento, por√©m, no momento dos treinos √© importante **ir testando** e analisando os resultados para poder escolher par√¢metros bons para se iniciar o treinamento do modelo. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
